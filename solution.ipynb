{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's do all of the imports. We use music21 for Computer-Aided Musical Analysis and Computational Musicology. \n",
    "Glob to read all the training files. Some LSTM models and layers from keras, and some standard liberaries like numpy and tqdm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're gonna read files repeatedly so let's a create a function that reads a single MIDI file. Function `extract_notes_from_piano` gets the piano notes from a MIDI file using a helper function called `_parse_notes_from_part`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_notes_from_piano(file_path):\n",
    "    notes = []\n",
    "\n",
    "    midi = converter.parse(file_path)\n",
    "    instr_stream = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    for part in instr_stream.parts:\n",
    "        if 'Piano' in str(part):\n",
    "            notes.extend(_parse_notes_from_part(part))\n",
    "\n",
    "    return notes\n",
    "\n",
    "def _parse_notes_from_part(part):\n",
    "    notes = []\n",
    "    notes_to_parse = part.recurse()\n",
    "\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the files that will create our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:10<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Notes: 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_unique_notes_from_directory(directory):\n",
    "    all_files = glob.glob(f'All Midi Files/{directory}/*.mid', recursive=True)\n",
    "\n",
    "    # Extract notes from each MIDI file and store in an array\n",
    "    notes_array = [extract_notes_from_piano(file) for file in tqdm(all_files, position=0, leave=True)]\n",
    "\n",
    "    # Flatten the notes_array and get unique notes\n",
    "    flat_notes = [note for notes in notes_array for note in notes]\n",
    "    unique_notes = list(set(flat_notes))\n",
    "    notess = sum(notes_array,[]) \n",
    "\n",
    "    return unique_notes, notess, notes_array\n",
    "\n",
    "file_path = \"schumann\"\n",
    "unique_notes, notess, notes_array = get_unique_notes_from_directory(file_path)\n",
    "print(\"Unique Notes:\", len(unique_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some utility variables for training and inferance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequency notes\n",
      "30 : 121\n",
      "50 : 97\n",
      "70 : 79\n",
      "90 : 64\n"
     ]
    }
   ],
   "source": [
    "threshold = 50\n",
    "timesteps = 50\n",
    "\n",
    "# The frequency (count) of each note\n",
    "# We will use these values to filter the note set in order to make training faster\n",
    "freq = {note: notess.count(note) for note in unique_notes}\n",
    "\n",
    "# Get how many notes have frequency of more than 30, more than 50, etc\n",
    "print(\"\\nFrequency notes\")\n",
    "for i in range(30, 100, 20):\n",
    "    threshold_notes = {note: count for note, count in freq.items() if count >= i}\n",
    "    print(i, \":\", len(threshold_notes))\n",
    "\n",
    "# Remove notes with frequency greater than threshold, e.g., 50\n",
    "freq_notes = {note: count for note, count in freq.items() if count >= threshold}\n",
    "\n",
    "# Create new notes using the frequent notes\n",
    "new_notes = [[note for note in notes if note in freq_notes] for notes in notes_array]\n",
    "\n",
    "# Dictionary with key as note index and value as note\n",
    "ind2note = dict(enumerate(freq_notes.keys()))\n",
    "\n",
    "# Dictionary with key as note and value as note index\n",
    "note2ind = {note: index for index, note in ind2note.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the input and output sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = [], []\n",
    "\n",
    "for notes in new_notes:\n",
    "    for j in range(0, len(notes) - timesteps):\n",
    "        # Input will be the current index + timestep\n",
    "        # Output will be the next index after timestep\n",
    "        # To create a seq2seq input output chain\n",
    "        inp = notes[j: j + timesteps]\n",
    "        out = notes[j + timesteps]\n",
    "\n",
    "        # Append the index value of respective notes\n",
    "        x.append([note2ind[note] for note in inp])\n",
    "        y.append(note2ind[out])\n",
    "\n",
    "x_new = np.array(x)\n",
    "y_new = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = np.reshape(x_new, (len(x_new), timesteps, 1))\n",
    "y_new = np.reshape(y_new, (-1, 1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_new, y_new, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model. We will use a two stacked LSTM layer with the latent dimension of 256 with 2 dropout layers between them. Finally we will the last dropout layer to a fully connected layer of dimension 256 and finally connect it to an output layer of dimension `len(note2ind)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 50, 256)           264192    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50, 256)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 97)                24929     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 880,225\n",
      "Trainable params: 880,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(256, return_sequences=True, input_shape=(x_new.shape[1], x_new.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(len(note2ind), activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model. We use `sparse_categorical_crossentropy` because we have 97 class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "109/109 [==============================] - 32s 266ms/step - loss: 4.3310 - accuracy: 0.0333 - val_loss: 4.3236 - val_accuracy: 0.0387\n",
      "Epoch 2/60\n",
      "109/109 [==============================] - 28s 257ms/step - loss: 4.2993 - accuracy: 0.0385 - val_loss: 4.2947 - val_accuracy: 0.0404\n",
      "Epoch 3/60\n",
      "109/109 [==============================] - 28s 258ms/step - loss: 4.2766 - accuracy: 0.0375 - val_loss: 4.2947 - val_accuracy: 0.0410\n",
      "Epoch 4/60\n",
      "109/109 [==============================] - 41s 378ms/step - loss: 4.2474 - accuracy: 0.0391 - val_loss: 4.2764 - val_accuracy: 0.0416\n",
      "Epoch 5/60\n",
      "109/109 [==============================] - 31s 286ms/step - loss: 4.2164 - accuracy: 0.0390 - val_loss: 4.2327 - val_accuracy: 0.0427\n",
      "Epoch 6/60\n",
      "109/109 [==============================] - 29s 262ms/step - loss: 4.1805 - accuracy: 0.0437 - val_loss: 4.2016 - val_accuracy: 0.0421\n",
      "Epoch 7/60\n",
      "109/109 [==============================] - 27s 245ms/step - loss: 4.1253 - accuracy: 0.0517 - val_loss: 4.1896 - val_accuracy: 0.0485\n",
      "Epoch 8/60\n",
      "109/109 [==============================] - 26s 234ms/step - loss: 4.0586 - accuracy: 0.0605 - val_loss: 4.1448 - val_accuracy: 0.0465\n",
      "Epoch 9/60\n",
      "109/109 [==============================] - 25s 234ms/step - loss: 3.9811 - accuracy: 0.0694 - val_loss: 4.0689 - val_accuracy: 0.0595\n",
      "Epoch 10/60\n",
      "109/109 [==============================] - 26s 236ms/step - loss: 3.8862 - accuracy: 0.0786 - val_loss: 4.0140 - val_accuracy: 0.0655\n",
      "Epoch 11/60\n",
      "109/109 [==============================] - 26s 234ms/step - loss: 3.7845 - accuracy: 0.0961 - val_loss: 3.9609 - val_accuracy: 0.0779\n",
      "Epoch 12/60\n",
      "109/109 [==============================] - 25s 233ms/step - loss: 3.6554 - accuracy: 0.1093 - val_loss: 3.9201 - val_accuracy: 0.0875\n",
      "Epoch 13/60\n",
      "109/109 [==============================] - 26s 242ms/step - loss: 3.5435 - accuracy: 0.1319 - val_loss: 3.8572 - val_accuracy: 0.0944\n",
      "Epoch 14/60\n",
      "109/109 [==============================] - 26s 236ms/step - loss: 3.4010 - accuracy: 0.1538 - val_loss: 3.8485 - val_accuracy: 0.1100\n",
      "Epoch 15/60\n",
      "109/109 [==============================] - 26s 242ms/step - loss: 3.2748 - accuracy: 0.1749 - val_loss: 3.8016 - val_accuracy: 0.1224\n",
      "Epoch 16/60\n",
      "109/109 [==============================] - 26s 238ms/step - loss: 3.1373 - accuracy: 0.2060 - val_loss: 3.7857 - val_accuracy: 0.1296\n",
      "Epoch 17/60\n",
      "109/109 [==============================] - 26s 238ms/step - loss: 3.0140 - accuracy: 0.2301 - val_loss: 3.7739 - val_accuracy: 0.1311\n",
      "Epoch 18/60\n",
      "109/109 [==============================] - 26s 240ms/step - loss: 2.8653 - accuracy: 0.2544 - val_loss: 3.7388 - val_accuracy: 0.1438\n",
      "Epoch 19/60\n",
      "109/109 [==============================] - 27s 252ms/step - loss: 2.7200 - accuracy: 0.2874 - val_loss: 3.7503 - val_accuracy: 0.1455\n",
      "Epoch 20/60\n",
      "109/109 [==============================] - 26s 239ms/step - loss: 2.5821 - accuracy: 0.3160 - val_loss: 3.7559 - val_accuracy: 0.1640\n",
      "Epoch 21/60\n",
      "109/109 [==============================] - 26s 238ms/step - loss: 2.4676 - accuracy: 0.3449 - val_loss: 3.7280 - val_accuracy: 0.1738\n",
      "Epoch 22/60\n",
      "109/109 [==============================] - 26s 237ms/step - loss: 2.3387 - accuracy: 0.3700 - val_loss: 3.7658 - val_accuracy: 0.1689\n",
      "Epoch 23/60\n",
      "109/109 [==============================] - 26s 237ms/step - loss: 2.2288 - accuracy: 0.3920 - val_loss: 3.7726 - val_accuracy: 0.1836\n",
      "Epoch 24/60\n",
      "109/109 [==============================] - 27s 248ms/step - loss: 2.1028 - accuracy: 0.4279 - val_loss: 3.8118 - val_accuracy: 0.1810\n",
      "Epoch 25/60\n",
      "109/109 [==============================] - 27s 247ms/step - loss: 2.0180 - accuracy: 0.4414 - val_loss: 3.8049 - val_accuracy: 0.1934\n",
      "Epoch 26/60\n",
      "109/109 [==============================] - 28s 261ms/step - loss: 1.8938 - accuracy: 0.4702 - val_loss: 3.8331 - val_accuracy: 0.2012\n",
      "Epoch 27/60\n",
      "109/109 [==============================] - 27s 247ms/step - loss: 1.7992 - accuracy: 0.4989 - val_loss: 3.8614 - val_accuracy: 0.2076\n",
      "Epoch 28/60\n",
      "109/109 [==============================] - 26s 238ms/step - loss: 1.6976 - accuracy: 0.5157 - val_loss: 3.9259 - val_accuracy: 0.2076\n",
      "Epoch 29/60\n",
      "109/109 [==============================] - 26s 238ms/step - loss: 1.6181 - accuracy: 0.5394 - val_loss: 3.9735 - val_accuracy: 0.2139\n",
      "Epoch 30/60\n",
      "109/109 [==============================] - 26s 239ms/step - loss: 1.5411 - accuracy: 0.5580 - val_loss: 4.0261 - val_accuracy: 0.2252\n",
      "Epoch 31/60\n",
      "109/109 [==============================] - 26s 238ms/step - loss: 1.4566 - accuracy: 0.5745 - val_loss: 4.0151 - val_accuracy: 0.2315\n",
      "Epoch 32/60\n",
      "109/109 [==============================] - 26s 239ms/step - loss: 1.3672 - accuracy: 0.6017 - val_loss: 4.0801 - val_accuracy: 0.2431\n",
      "Epoch 33/60\n",
      "109/109 [==============================] - 26s 235ms/step - loss: 1.2896 - accuracy: 0.6253 - val_loss: 4.1328 - val_accuracy: 0.2341\n",
      "Epoch 34/60\n",
      "109/109 [==============================] - 26s 239ms/step - loss: 1.2337 - accuracy: 0.6361 - val_loss: 4.2083 - val_accuracy: 0.2379\n",
      "Epoch 35/60\n",
      "109/109 [==============================] - 26s 239ms/step - loss: 1.1751 - accuracy: 0.6569 - val_loss: 4.2862 - val_accuracy: 0.2436\n",
      "Epoch 36/60\n",
      "109/109 [==============================] - 25s 232ms/step - loss: 1.0994 - accuracy: 0.6730 - val_loss: 4.3210 - val_accuracy: 0.2491\n",
      "Epoch 37/60\n",
      "109/109 [==============================] - 26s 239ms/step - loss: 1.0527 - accuracy: 0.6891 - val_loss: 4.3330 - val_accuracy: 0.2529\n",
      "Epoch 38/60\n",
      "109/109 [==============================] - 26s 236ms/step - loss: 1.0056 - accuracy: 0.6979 - val_loss: 4.3775 - val_accuracy: 0.2589\n",
      "Epoch 39/60\n",
      "109/109 [==============================] - 26s 237ms/step - loss: 0.9630 - accuracy: 0.7122 - val_loss: 4.4467 - val_accuracy: 0.2575\n",
      "Epoch 40/60\n",
      "109/109 [==============================] - 26s 235ms/step - loss: 0.9091 - accuracy: 0.7242 - val_loss: 4.4889 - val_accuracy: 0.2613\n",
      "Epoch 41/60\n",
      "109/109 [==============================] - 26s 238ms/step - loss: 0.8545 - accuracy: 0.7399 - val_loss: 4.5970 - val_accuracy: 0.2569\n",
      "Epoch 42/60\n",
      "109/109 [==============================] - 26s 239ms/step - loss: 0.8063 - accuracy: 0.7581 - val_loss: 4.6831 - val_accuracy: 0.2569\n",
      "Epoch 43/60\n",
      "109/109 [==============================] - 26s 237ms/step - loss: 0.7880 - accuracy: 0.7612 - val_loss: 4.7015 - val_accuracy: 0.2667\n",
      "Epoch 44/60\n",
      "109/109 [==============================] - 26s 238ms/step - loss: 0.7487 - accuracy: 0.7694 - val_loss: 4.7512 - val_accuracy: 0.2647\n",
      "Epoch 45/60\n",
      "109/109 [==============================] - 26s 236ms/step - loss: 0.7193 - accuracy: 0.7786 - val_loss: 4.8231 - val_accuracy: 0.2673\n",
      "Epoch 46/60\n",
      "109/109 [==============================] - 26s 237ms/step - loss: 0.6721 - accuracy: 0.7957 - val_loss: 4.8657 - val_accuracy: 0.2682\n",
      "Epoch 47/60\n",
      "109/109 [==============================] - 26s 241ms/step - loss: 0.6621 - accuracy: 0.7978 - val_loss: 4.8728 - val_accuracy: 0.2685\n",
      "Epoch 48/60\n",
      "109/109 [==============================] - 26s 238ms/step - loss: 0.6091 - accuracy: 0.8178 - val_loss: 4.9824 - val_accuracy: 0.2760\n",
      "Epoch 49/60\n",
      "109/109 [==============================] - 26s 242ms/step - loss: 0.6058 - accuracy: 0.8132 - val_loss: 5.0237 - val_accuracy: 0.2708\n",
      "Epoch 50/60\n",
      "109/109 [==============================] - 26s 235ms/step - loss: 0.5882 - accuracy: 0.8180 - val_loss: 5.0504 - val_accuracy: 0.2754\n",
      "Epoch 51/60\n",
      "109/109 [==============================] - 26s 240ms/step - loss: 0.5620 - accuracy: 0.8294 - val_loss: 5.0783 - val_accuracy: 0.2771\n",
      "Epoch 52/60\n",
      "109/109 [==============================] - 26s 237ms/step - loss: 0.5474 - accuracy: 0.8326 - val_loss: 5.1395 - val_accuracy: 0.2745\n",
      "Epoch 53/60\n",
      "109/109 [==============================] - 25s 234ms/step - loss: 0.5299 - accuracy: 0.8381 - val_loss: 5.2640 - val_accuracy: 0.2725\n",
      "Epoch 54/60\n",
      "109/109 [==============================] - 26s 235ms/step - loss: 0.5039 - accuracy: 0.8463 - val_loss: 5.2308 - val_accuracy: 0.2731\n",
      "Epoch 55/60\n",
      "109/109 [==============================] - 26s 238ms/step - loss: 0.4809 - accuracy: 0.8520 - val_loss: 5.2867 - val_accuracy: 0.2789\n",
      "Epoch 56/60\n",
      "109/109 [==============================] - 26s 239ms/step - loss: 0.4807 - accuracy: 0.8529 - val_loss: 5.3409 - val_accuracy: 0.2803\n",
      "Epoch 57/60\n",
      "109/109 [==============================] - 26s 236ms/step - loss: 0.4582 - accuracy: 0.8589 - val_loss: 5.4093 - val_accuracy: 0.2754\n",
      "Epoch 58/60\n",
      "109/109 [==============================] - 26s 235ms/step - loss: 0.4338 - accuracy: 0.8670 - val_loss: 5.4376 - val_accuracy: 0.2806\n",
      "Epoch 59/60\n",
      "109/109 [==============================] - 26s 238ms/step - loss: 0.4395 - accuracy: 0.8647 - val_loss: 5.5027 - val_accuracy: 0.2774\n",
      "Epoch 60/60\n",
      "109/109 [==============================] - 26s 238ms/step - loss: 0.4226 - accuracy: 0.8691 - val_loss: 5.5398 - val_accuracy: 0.2748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: seq2seq\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: seq2seq\\assets\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=128, epochs=60, \n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "\n",
    "model.save(\"seq2seq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference. Let's create some music. We will pick a random note from the test set to be our starting input sequence then we will predict the next note, append it to our current sequence and repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "num_of_notes = 200\n",
    "\n",
    "# Get some random data from x_test to be the start\n",
    "# of the output sequence \n",
    "music_pattern = x_test[np.random.randint(0, len(x_test) - 1)]\n",
    "\n",
    "out_pred = []  # It will store predicted notes\n",
    "\n",
    "for _ in range(num_of_notes):\n",
    "    music_pattern = music_pattern.reshape(1, len(music_pattern), 1)\n",
    "\n",
    "    # Get the maximum probability value from the predicted output\n",
    "    pred_index = np.argmax(model.predict(music_pattern))\n",
    "\n",
    "    # Get the note using the predicted index and append to the output prediction list\n",
    "    out_pred.append(ind2note[pred_index])\n",
    "\n",
    "    # Update the music pattern with one timestep ahead\n",
    "    music_pattern = np.append(music_pattern, pred_index)\n",
    "    music_pattern = music_pattern[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Saving the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output.mid'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_notes = []\n",
    "\n",
    "for offset, pattern in enumerate(out_pred):\n",
    "    # If pattern is a chord instance\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        # Split notes from the chord\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        notes = []\n",
    "\n",
    "        for current_note in notes_in_chord:\n",
    "            i_curr_note = int(current_note)\n",
    "            # Create a Note object for the current note and append it\n",
    "            new_note = note.Note(i_curr_note)\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(new_note)\n",
    "\n",
    "        # Create a Chord object for the chord\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "\n",
    "    else:\n",
    "        # Create a Note object for the single note, apply the offset, and append it\n",
    "        new_note = note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "# Save the MIDI file\n",
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp='output.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
